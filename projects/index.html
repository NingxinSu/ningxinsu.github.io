<!doctype html><html lang=en><head><title>Projects ::
Ningxin Su
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=/projects/><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/img/favicon.png><link href=/fonts/Inter-Italic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-Regular.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-Medium.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-MediumItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-Bold.woff2 rel=preload type=font/woff2 as=font crossorigin><link href=/fonts/Inter-BoldItalic.woff2 rel=preload type=font/woff2 as=font crossorigin><meta name=twitter:card content="summary"><meta name=twitter:title content="Projects"><meta property="og:url" content="/projects/"><meta property="og:site_name" content="Ningxin Su"><meta property="og:title" content="Projects"><meta property="og:locale" content="en"><meta property="og:type" content="website"><link rel=alternate type=application/rss+xml href=/projects/index.xml title="Ningxin Su"></head><body class=light-theme><div class=container><header class=header><span class=header__inner><a href=/ class=logo style=text-decoration:none><span class=logo__mark><svg class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg>
</span><span class=logo__text>Ningxin Su</span>
<span class=logo__cursor></span>
</a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/publications>Publications</a></li><li><a href=/awards>Awards</a></li><li><a href=/teaching>Teaching</a></li><li><a href=/professional_services>Professional Services</a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/publications>Publications</a></li><li><a href=/awards>Awards</a></li><li><a href=/teaching>Teaching</a></li><li><a href=/professional_services>Professional Services</a></li></ul></nav><span class=menu-trigger><svg viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg>
</span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><div class=posts><article class="post on-list"><h1 class=post-title><a href=/projects/infocom23/>Asynchronous Federated Unlearning</a></h1><div class=post-meta></div><div class=post-content><p><strong>Ningxin Su</strong>, Baochun Li, University of Toronto,<br><em>IEEE International Conference on Computer Communications (INFOCOM) 2023</em><br>[<a href=/assets/infocom23.pdf>Paper</a>] [<a href=/assets/infocom23_slides.pdf>Slides</a>] [<a href=https://github.com/TL-System/plato/tree/main/examples/knot>Source Code</a>]</p><p>Thanks to regulatory policies such as the General Data Protection Regulation (GDPR), it is essential to provide users with the <em>right to erasure</em> regarding their own private data, even if such data has been used to train a neural network model. Such a <em>machine unlearning</em> problem becomes even more challenging in the context of federated learning. where clients collaborate to train a global model with their private data. When a client requests that its data be erased, its effects have already gradually permeated through a large number of clients, as the server aggregates client updates over multiple communication rounds. Thus, erasing data samples from one client requires a large number of clients to engage in a retraining process.</p></div><div><a class="read-more button" href=/projects/infocom23/>Read more →</a></div></article><article class="post on-list"><h1 class=post-title><a href=/projects/iwqos22/>How Asynchronous can Federated Learning Be?</a></h1><div class=post-meta></div><div class=post-content><p><strong>Ningxin Su</strong>, Baochun Li, University of Toronto,<br><em>IEEE International Symposium on Quality of Service (IWQoS) 2022</em><br>[<a href=/assets/iwqos22.pdf>Paper</a>] [<a href=/assets/port_slides.pdf>Slides</a>] [<a href=https://github.com/TL-System/plato/tree/main/examples/port>Source Code</a>]</p><p>As a practical paradigm designed to involve large numbers of edge devices in distributed training of deep learning models, federated learning has witnessed a significant amount of research attention in the recent years. Yet, most existing mechanisms on federated learning assumed either fully synchronous or asynchronous communication strategies between clients and the federated learning server. Existing designs that were partially asynchronous in their communication were simple heuristics, and were evaluated using the number of communication rounds or updates required for convergence, rather than the wall-clock time in practice.</p></div><div><a class="read-more button" href=/projects/iwqos22/>Read more →</a></div></article><div class=pagination><div class=pagination__buttons></div></div></div></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user">Ningxin Su &copy; 20252025</div></div></footer><script type=text/javascript src=/bundle.min.js></script></div></body></html>